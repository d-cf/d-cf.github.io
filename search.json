[{"title":"ADS chapter6 Binomial Queue","date":"2021-06-03T12:23:00.000Z","url":"/2021/06/03/ADS-chapter6/","categories":[["Demo","/categories/Demo/"]],"content":"Binomial Queue​ Target: 为什么有了Binomial Queue？优化Leftist heaps和Skew heaps的insert操作！(但是我感觉ppt上说的不太对，对于一个普通的堆来说，插入操作的时间复杂度为log(N)，对于Leftist heaps和Skew heaps也是log(N)；有N个数字，然后建堆，普通堆的总时间为O(N)，Leftit heaps和Skew heaps也是O(N)，从这点上来看他们并没有什么优劣。所以说ppt上说Binomial Queue优化insert是对的，但是例子不太恰当)(个人观点) Structure​ A binomial queue is not a heap-ordered tree, but rather a collection of heap-ordered trees, known as a forest. Each heap-ordered tree is a binomial tree. ​ A binomial tree of height 0 is a one-node tree. A binomial tree, Bk , of height k is formed by attaching a binomial tree, Bk – 1 , to the root of another binomial tree, Bk – 1 . ​ (详情见ppt) ​ Observation :Bk consists of a root with k children, which are B0 B1 B2 ……Bk-1 ,Bk has exactly 2k nodes. The number of nodes at depth d is C(k,d). ​ A priority queue of any size can be uniquely represented by a collection of binomial trees. .(一个数能够唯一地用二进制表示) Operations:FindMin:​ The minimum key is in one of the roots. There are at most logN(取上界) roots, hence Tp = O(logN). ​ Note: We can remember the minimum and update whenever it is changed. Then this operation will take O(1).(但是会额外消耗空间) Merge:​ 只需要把相同大小的子树相互连接即可，所以时间复杂度比较低，为O(logN) Insert:​ a special case for merging ​ Note: If the smallest nonexistent binomial tree is Bi , then Tp = Const · (i + 1).Performing N Inserts on an initially empty binomial queue will take O(N) worst-case time. Hence the average time is constant. DeleteMin(H)；​ Step 1: FindMin in Bk O(logN) ​ Step 2: Remove Bk from H O(1) ​ Step 3: Remove root from Bk O(logN) ​ Step 4: Merge(H’,H’’) O(logN) 代码: Tp =O(1) 【Claim】proof 1: A binomial queue of N elements can be built by N successive insertions in O(N) time. Total steps = N; Total links=N(1/4+21/8+31/16……)=O(N) proof 2: Proof 2: An insertion that costs c units results in a net increase of 2 – c trees in the forest. Ci ::= cost of the ith insertion Pi ::= number of trees after the ith insertion (P0 = 0) Ci + (Pi – Pi-1 )= 2 for all i = 1, 2, …, N Add all these equations up Ci (加和)+PN -P0 =2N Ci (加和)=2N-PN &lt;=2N=O(N) Tworst = O(log N), but Tamortized = 2"},{"title":"ADS chapter5 Skew Heaps","date":"2021-06-02T12:57:00.000Z","url":"/2021/06/02/ADS-chapter5/","categories":[["Demo","/categories/Demo/"]],"content":"Skew Heaps​ At first we should know that the relation between Leftist Heap and the Skew Heap is much similar to the relation between the AVL tree and the Splay tree. ​ Similarly skew heaps are also a simple version of the leftist heaps, in leftist tree we must keep an eye on the Npl, but in skew heap we don’t care about it anymore, we just blindly swap the children. Target: Any M consecutive operations take at most O(MlogN) time. ​ 这里主要看Merge操作 ​ Merge: Always swap the left and right children except that the largest of all the nodes on the right paths does not have its children swapped(如果不理解这句话请看ppt，其上有演示). No Npl. (整个merge的过程在ppt上有详细操作，不在列举) ​ Note: Skew heaps have the advantages that no extra space is required to maintain path lengths and no tests are required to determine when to swap children. ​ It is an open problem to determine precisely the expected right path length of both leftist and skew heaps.(注意这里说的是expected path length 相当于average，我已知Leftist heaps的最大right path length 是O(logN),对于skew heaps 我们可以证明它的amortized right path length是log(N)但是不知道expected path length) Amortized Analysis for Skew Heaps​ Insert &amp; DeleteMin are just Merge.(因为insert其实是Merge的一种特殊情况，DeleteMin是删除根节点再加上Merge)，so if we can prove that each merge will take an amortized logN time,then we are done. ​ Assume that the amortized time of Merge is Tamortized =O(log(N)) ​ we can prove by potential function method ​ Di = the root of the resulting tree. ​ P(Di )=number of right nodes? —&gt;not work. Why? because when we do the amortized analysis, we always assume that we start from the empty cases,so at very beginning,we have two empty heaps which means the initial value of this function is 0. And after a sequence of operations, the number of right nodes is guaranteed to be nonnegative. It satisfy the basic requirements,but this function is guaranteed to be an increasing function, or say a non-decreasing function.(因为开始时右节点是右节点，经过一次Merge之后变成左节点，下一次Merge后左边部分经过了插入再变为右节点，所以是递增的)，而一个potential function 需要反映出是好的还是坏的情况，这样的递增的是无法判断的，所以不行。 ​ so we define P(Di) = number of the heavy nodes. ​ Definition: A node p is heavy if the number of descendants of p’s right subtree is at least half of the number of descendants of p, and light otherwise. Note that the number of descendants of a node includes the node itself.(its right subtree is larger than its left subtree). ​ The only nodes whose heavy/light status can change are nodes that are initially on the right path.(在最右面路径上的heavy 必然变为light，但是最右面路径上的light不一定变为heavy) ​ 所以定义Hi :li +hi (i=1 or 2)(number of nodes along the right path)———&gt; Tworst =l1 +h1 +l2 +h2 Before merge:Pi =h1 +h2 +h ———-&gt;Tamortized =Tworst +Pi+1 -Pi &lt;=2(l1 +l2 ) After merge : Pi+1 &lt;=l1 +l2 +h ​ . ​ ​ "},{"title":"ADS chapter4 Leftist Heaps","date":"2021-06-01T05:19:00.000Z","url":"/2021/06/01/ADS-chapter4/","categories":[["Demo","/categories/Demo/"]],"content":"Leftist Heapstarget: speed up merging in O(N). ​ 普通堆的特性：structure property + order property（储存在binary tree中，而且是有序的，上面的都比下面的小或者大） ​ merge two heaps if we only use the original heap structure: O(N). ​ 这是确定的N，而不是O(N),因为copy所有的节点需要N，而下滤操作也需要N，这样就是N了 ​ if we use pointers ,we will slow down all the operations. (这是没有办法的事，想降低merge的时间复杂度就势必会用指针，而指针操作会降低速度，权衡之下左式堆用了指针)，总的来讲，从算法上说左式堆和普通的二叉堆相比，insert、deleteMin的时间复杂度没有变化，都是O(logN),但是降低了Merge的时间复杂度从N变为了O(logN),只是算法理论上。而建堆操作的话，普通的是O(N),左式堆也能算，就是把每个单个节点看成一个优先队列（堆），然后merge，然后又得到一些两个节点的堆，再merge，然后得到一些4个节点的堆，再merge……，（最后是多少我懒得算，但是一定能算，偷偷告诉你我算出来是O(N),和普通的堆一样……)。所以从算法角度上讲左式堆更加好。 ​ order property–the same ​ structure property–binary tree,but unbalanced. ​ Definition: The null path length,Npl(X), of any node X is the length of the shortest path from X to a node without two children. Define Npl(NULL)=-1. Note: Npl(X)=min{Npl(C)+1 for all C as children of X} ​ Definition: The Leftist heap property is that for every node X in the heap, the null path length of the left child is at least as large as that of the right child. ​ Theorem: A Leftist tree with r nodes on the right path must have at least 2r -1 nodes. ​ How long is the right path of a Leftist tree of N nodes?—–&gt;at most log(N+1)==O(logN) ​ If we can perform all the work on the right path,which is guaranteed to be short. ​ trouble maker: insert and merge(我觉得主要是merge是N的操作，而在普通的堆中insert的操作是O(logN))(insert is merely a special case of merging) Declaration: Merge(recusive version)Step 1: Merge(H1-&gt;Right,H2) Step 2: Attach(H2,H1-&gt;Right) Step 3: Swap(H1-&gt;Right,H1-&gt;Left) (if necessary) ​ T=O(log(N)) 从递归的形式上是看不出来的，建议从非递归形式上看，非递归形式也有助于做一些题目，一定要看！（见ppt，在这里无法像ppt一样一步步来） DeleteMin​ Step 1:delete the root; ​ Step 2: Merge the two subtrees Tp =O(logN) easy to think. ​ "},{"date":"2021-05-31T01:54:34.129Z","url":"/2021/05/31/NP%20problems/","categories":[["undefined",""]]},{"title":"ADS chapter3 B+ Tree","date":"2021-05-30T06:53:00.000Z","url":"/2021/05/30/ADS-chapter3/","categories":[["Demo","/categories/Demo/"]],"content":"B+ TreeDefinition: A B+ tree of order M is a tree with the following structural properties: (1) The root is either a leaf or has between 2 and M children. (2) All nonleaf nodes (except the root) have between M/2 (取上界)and M children. (3) All leaves are at the same depth.(Assume each nonroot leaf also has between M/2 (取上界) and M children ) search、insert操作原理比较简单，不再过多重复 先粘贴insert的伪码： Depth(M,N)=O(logM/2 N) T(M,N)=O((M/logM)logN) TFind (M,N)=O(logN)(因为find操作的时间复杂度只依赖于该点的深度即Depth(M,N)). delete的操作:(可能不是重点，因为mooc上没讲，但是还是了解一下比较好~)。 1）删除叶子结点中对应的key。删除后若结点的key的个数大于等于M/2 取上界，删除操作结束,否则执行第2步。 2）若兄弟结点key有富余（大于M/2(取上界)），向兄弟结点借一个记录，同时用借到的key替换父结（指当前结点和兄弟结点共同的父结点）点中的key，删除结束。否则执行第3步。 3）若兄弟结点中没有富余的key,则当前结点和兄弟结点合并成一个新的叶子结点，并删除父结点中的key（父结点中的这个key两边的孩子指针就变成了一个指针，正好指向这个新的叶子结点），将当前结点指向父结点（必为索引结点），执行第4步（第4步以后的操作和B树就完全一样了，主要是为了更新索引结点）。 4）若索引结点的key的个数大于等于M/2(取上界)，则删除操作结束。否则执行第5步 5）若兄弟结点有富余，父结点key下移，兄弟结点key上移，删除结束。否则执行第6步 6）当前结点和兄弟结点及父结点下移key合并成一个新的结点。将当前结点指向父结点，重复第4步。 ***注意，通过B+树的删除操作后，索引结点中存在的key，不一定在叶子结点中存在对应的记录。"},{"title":"ADS chapter2 RB Tree","date":"2021-05-29T08:33:00.000Z","url":"/2021/05/29/ADS-chapter2/","tags":[["AVL Tree","/tags/AVL-Tree/"],["Splay Tree","/tags/Splay-Tree/"]],"categories":[["Demo","/categories/Demo/"]],"content":"Red and Black TreesTarget: Balanced binary search tree 结构：一般键值，左孩子指针、右孩子指针、父指针，颜色域。 Definition: binary search tree ​ (1) every node is either red or black ​ (2)root is black ​ (3) every leaf is black ​ (4) if a node is red,then both its children are black; ​ (5)For each node,all simple paths from the node to descendant leaves contain the same number of black nodes. Definition: The black-height of any node x—-&gt;(bh(x)), is the number of black nodes on any simple path from x(x is not included) down to a leaf. bh(Tree)=bh(root). Lemma :A red-black tree with N internal nodes has height at most 2ln(N+1). Proof: (1) For any node x,sizeof(x)&gt;=2bh(x) -1(归纳法证明)Prove by induction. ​ if h(x)=0,x is NULL —-&gt; sizeof(x)=0 √ ​ suppose it is true for all x with h(x)&lt;k. ​ For x with h(x)=k+1,bh(child)=bh(x)-1 or bh(x) ​ Since h(child)&lt;=k ,sizeof(child)&gt;=2bh(child) -1&gt;=2bh(x)-1 -1 ​ hence sizeof(x)=2*sizeof(child)+1&gt;=2bh(x) -1. Then sizeof(root)&gt;=2bh(x) -1,即N&gt;=2bh(x) -1,bh(tree)&lt;=log(N+1) if we can prove bh(tree)&gt;=h(tree)/2, then we can prove h(tree)&lt;=2*log(N+1). and bh(tree)&gt;=h(tree) is easy to prove. Insert 1、红色节点插入到黑色节点下，直接插入即可。 2、红色节点插入到红色节点下，插入之后需要交换父节点与祖父节点的颜色，红—-&gt;黑，黑—-&gt;红 当然这样做会导致祖父节点变为红色，当祖父节点的父节点也为红色时会产生冲突，也就是情况三。 3、（情况见2）具体情况说不清，见ADS的PPT 对称情况同上 插入时间复杂度 T=O(h)=O(lnN). Deletion 1、Delete a leaf node: Reset its parent link to NULL 2、Delete a degree 1 node: Replace the node by its single child. 3、Delete a degree 2 node: ​ (1)Replace the node by the largest one in its left subtree or the smallest one in its right subtree.(keep the color) ​ (2)Delete the replacing node from the subtree. (以上操作和binary tree的删除操作相同) ​ "},{"title":"ADS chapter1 AVL tree and Splay tree","date":"2021-05-29T08:33:00.000Z","url":"/2021/05/29/ADS-chapter1/","tags":[["AVL Tree","/tags/AVL-Tree/"],["Splay Tree","/tags/Splay-Tree/"]],"categories":[["Demo","/categories/Demo/"]],"content":"ADS chapter1AVL TreeTarget: speed up searching (with insertion and deletion) ​ (为什么不用binary search tree?虽然binary search tree的所有操作时间复杂度均为O(logN),即为与树高成正比，但是当最坏情况时，树高可能为O(N),使得binary search tree 的效果很不理想) Definition: An empty binary tree is height balanced. If T is a nonempty binary tree with T L and TR as its left and right subtree,then T is height balanced if and only if (1)TL and TR are height balanced,and (2)| hL - hR |&lt;=1 where hL and hR are the heights of TL and TR ,respectively. (The balanced factor BF(node)=hL - hR .In an AVL tree,BF(node)=-1 1 or 0) (注: height of an empty tree is defined to be -1) ​ AVL Tree 最重要的特性或者说需要掌握的是旋转，有single rotation还有double rotation,首先需要找到不平衡的节点（若有多个不平衡的节点，找最下面的），也就是|BF|&gt;1的点，然后看从该点到造成麻烦的节点是怎样走的，如果是LL或者RR，只需要一次右旋或者左旋即可；如果是LR，则先对中间节点进行一次左旋，转成LL，然后进行右旋；如果是RL，则先对中间节点进行一次右旋，变成RR，然后进行左旋即可。 ​ AVL Tree本身就是一个binary search tree，所以说AVL Tree的各项操作也是和树的高度成正比的，Tp =O(h)，那么height为多少？O(logN),证明如下： ​ Let nh be the minimum number of nodes in a height balanced tree of height h. Then the tree has a relation nh =nh-1 + nh-2 +1(looks like Fibonacci numbers),nh =Fh+2 -1, Fi ~(k)i (k为常数),所以nh ~(k)h ,得h=logn, height=O(logn).得证。 Splay TreeTarget: any M consecutive tree operations starting from an empty tree take at most O(MlogN) time.(AVL tree is a Splay tree but a Splay tree may be not an AVL tree). Idea: after the node is accessed, it is pushed to the root by aseries of AVL tree rotations. (查询、插入均如此) For any nonroot node X, denote its parent by P and grandparent by G. case 1:P is the root—–&gt; Rotate X and P case 2:P is not the root ——-&gt;zigzag : 两次旋转,P和X进行一次旋转，之后X和G再进行一次旋转. zigzig: 一次旋转,P和G直接进行一次旋转即可 (删除) Step 1:Find X(after that,X will be the root) Step 2: Remove X(after that there will be two subtrees TL TR ) Step 3: FindMax(TL );(左子树得最大元素会成为左子树得新根，这个子树一定没有右子树) Step 4: Make TR the right child of the root of TL "}]